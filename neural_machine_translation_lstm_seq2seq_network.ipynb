{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerlaxrex/keras-seq2seq-models/blob/main/neural_machine_translation_lstm_seq2seq_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aws84QfqDDm",
        "outputId": "8e10e77f-6fd4-4d83-ebce-0bddf1769c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datatable in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: afinn in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "! pip install datatable\n",
        "! pip install afinn\n",
        "! pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HRr6GbS1IHAh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datatable as dt\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from afinn import Afinn\n",
        "\n",
        "import sys, gc, re, time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, GRU, Attention, concatenate, LSTMCell\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z6AJ6JMyIHAr"
      },
      "outputs": [],
      "source": [
        "NUM_DATA = 300_000\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T14kC7beGwQt"
      },
      "source": [
        "**WARNING**: Before doing this step you need to go to Kaggle and generate the API token for your personal account. Then upload here on Colab the \"kaggle.json\" file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Uv0uI0cqR_e",
        "outputId": "47e3e034-2b42-45ff-a81e-4ba18bb83b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.5.18.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "nmtitalian2english.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  nmtitalian2english.zip\n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: _about.txt              \n",
            "  inflating: ita.txt                 \n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! \\cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d balamurugan1603/nmtitalian2english\n",
        "# ! kaggle datasets download -d yelp-dataset/yelp-dataset\n",
        "! unzip nmtitalian2english.zip\n",
        "# ! unzip yelp-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ua0SpP6-aIz"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "In the following cells we create the dataset with:\n",
        "1. the autoencoder generator data (src, tgt)\n",
        "2. the final positive/negative sentimento for the sentence (we delete the neutral sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Z37z6coeIHAt"
      },
      "outputs": [],
      "source": [
        "dataset = dt.fread('../content/ita.txt',fill=True,header=False,columns=['en','it','info']).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4EUju4JIIHAw"
      },
      "outputs": [],
      "source": [
        "def shuffle(df):\n",
        "    np.random.shuffle(df.values)\n",
        "\n",
        "def preprocess_sc(df):\n",
        "    df['src'] = df['en'].map(lambda x : re.sub( r'([!?.,;])', r' \\1', x)).map(lambda x : ' '.join(x.split()[::-1]))\n",
        "    df['tgt'] = df['it'].map(lambda x : re.sub( r'([!?.,;])', r' \\1', x))\n",
        "\n",
        "def delete_na(df):\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "def add_special_symbols(df):\n",
        "    df['tgt'] = df['tgt'].map(lambda x : '<SOS> ' + x + ' <EOS>') \n",
        "\n",
        "def preprocessing_text(df):\n",
        "    shuffle(df)\n",
        "    delete_na(df)\n",
        "    preprocess_sc(df)\n",
        "    add_special_symbols(df)\n",
        "    df.drop(columns=['info','it','en'], inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Fq-OxZKdIHAy"
      },
      "outputs": [],
      "source": [
        "data = preprocessing_text(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e03ABU_sIHA0",
        "outputId": "2dffa591-c12b-40d0-e033-d44b283773b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "src                       . child a as Japan to came Tom\n",
              "tgt    <SOS> Tom è venuto in Giappone da bambino . <EOS>\n",
              "Name: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data.iloc[100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JPKHt0A8L8J"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Uh_s41ewIHA1"
      },
      "outputs": [],
      "source": [
        "tokenizer_src = Tokenizer(num_words=20_000, filters='\"#$%&()*+-/=@[\\\\]^_`{|}~\\t\\n', oov_token='<oov>')\n",
        "tokenizer_src.fit_on_texts(data['src'])\n",
        "\n",
        "tokenizer_tgt = Tokenizer(num_words=20_000, filters='\"#$%&()*+-/=@[\\\\]^_`{|}~\\t\\n', oov_token='<oov>')\n",
        "tokenizer_tgt.fit_on_texts(data['tgt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RGCn5kwrIHA4"
      },
      "outputs": [],
      "source": [
        "src_sequences = tokenizer_src.texts_to_sequences(data['src'])\n",
        "tgt_sequences = tokenizer_tgt.texts_to_sequences(data['tgt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3qc82ymIHA6",
        "outputId": "a4122caa-7054-4b0c-cc22-a9cc18af5331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111 103\n"
          ]
        }
      ],
      "source": [
        "max_src_len = max(len(s) for s in src_sequences)\n",
        "max_tgt_len = max(len(s) for s in tgt_sequences)\n",
        "print(max_src_len, max_tgt_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMOGOokhIHA9",
        "outputId": "8cdbbf79-2cd2-4df1-c273-9c4ec825007c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data: 352_035, \n",
            "training data: 225_302, \n",
            "Validation data: 56_325, \n",
            "Test data: 70_407\n"
          ]
        }
      ],
      "source": [
        "tot_length = len(src_sequences)\n",
        "data_length = int(tot_length*0.8)\n",
        "train_length = int(data_length*0.8)\n",
        "valid_length = int(data_length*0.2)\n",
        "test_length = int(tot_length*0.2)\n",
        "print(f'Total data: {tot_length:_}, \\ntraining data: {train_length:_}, \\nValidation data: {valid_length:_}, \\nTest data: {test_length:_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Tc4vUWtdIHA-"
      },
      "outputs": [],
      "source": [
        "#Split the training, validation and test sets\n",
        "train_idx_end, valid_idx_start = train_length, train_length\n",
        "valid_idx_end = train_length+valid_length\n",
        "test_idx_start = train_length+valid_length\n",
        "\n",
        "train_sequences = [src_sequences[:train_idx_end], tgt_sequences[:train_idx_end]]\n",
        "valid_sequences = [src_sequences[valid_idx_start:valid_idx_end], tgt_sequences[valid_idx_start:valid_idx_end]]\n",
        "test_sequences = [src_sequences[test_idx_start:], tgt_sequences[test_idx_start:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE839DUBIHBA",
        "outputId": "928de771-ad37-4902-b722-96919b329d2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('. truth the telling in hesitation no have i',\n",
              " '<sos> non ho alcuna esitazione a dire la verità . <eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Try the preprocessing\n",
        "src_str = ' '.join(tokenizer_src.index_word[i] for i in train_sequences[0][0])\n",
        "tgt_str = ' '.join(tokenizer_tgt.index_word[i] for i in train_sequences[1][0])\n",
        "src_str, tgt_str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZQXcy61CgiM"
      },
      "source": [
        "## Prepare the Encoder Decoder Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "FEy6Ax_WiJAQ"
      },
      "outputs": [],
      "source": [
        "BS_TRAIN = 64\n",
        "BS_VALID = 32\n",
        "SPE_TRAIN = len(train_sequences[0])//BS_TRAIN\n",
        "SPE_VALID = len(valid_sequences[0])//BS_VALID\n",
        "EPOCHS = 1\n",
        "\n",
        "def create_dataset(src_seqs, tgt_seqs, bs_size, maxlen=20, padding='post'):\n",
        "  tgt_1 = [w[:-1] for w in tgt_seqs]\n",
        "  tgt_2 = [w[1:] for w in tgt_seqs]\n",
        "\n",
        "  src_ds = tf.data.Dataset.from_tensor_slices((pad_sequences(src_seqs, maxlen=20, padding='post'), \n",
        "                                              pad_sequences(tgt_1, maxlen=20, padding='post')))\n",
        "  tgt_ds = tf.data.Dataset.from_tensor_slices(pad_sequences(tgt_2, maxlen=20, padding='post'))\n",
        "\n",
        "  gen_ds = tf.data.Dataset.zip((src_ds, tgt_ds))\n",
        "  gen_ds = gen_ds.repeat().shuffle(1000).batch(bs_size).prefetch(1)\n",
        "  return gen_ds\n",
        "\n",
        "gen_train_ds = create_dataset(train_sequences[0], train_sequences[1], bs_size=BS_TRAIN)\n",
        "gen_valid_ds = create_dataset(valid_sequences[0], valid_sequences[1], bs_size=BS_VALID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4txGQWgX8YbB"
      },
      "source": [
        "## Encoder/Decoder Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "kbfYVtTcIHBG"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_words, embedding_size=100, lstm_out_dim = 128, name='Encoder_model'):\n",
        "        super(Encoder,self).__init__(name=name)\n",
        "        self.lstm_output_dim = lstm_out_dim\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding_layer = Embedding(input_dim=num_words+1,\n",
        "                                         output_dim=self.embedding_size,\n",
        "                                         mask_zero = True,\n",
        "                                         name='Encoder_embedding')\n",
        "        \n",
        "        self.lstm_layer = LSTM(units = self.lstm_output_dim, \n",
        "                                return_sequences = True,\n",
        "                                return_state = True, \n",
        "                                name='Encoder_LSTM')\n",
        "    \n",
        "    def call(self, inputs, init_state = None):\n",
        "        #Return the state and last output of the encoder\n",
        "        x = self.embedding_layer(inputs)\n",
        "        mask = self.embedding_layer.compute_mask(inputs)\n",
        "        outs, h, c = self.lstm_layer(x, mask = mask, initial_state = init_state)\n",
        "        return outs, h, c\n",
        "\n",
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, latent_dim, name='Luong_Attention'):\n",
        "    super().__init__()\n",
        "    self.W1 = Dense(units=latent_dim)\n",
        "    self.W2 = Dense(units=latent_dim)\n",
        "    self.attn = Attention()\n",
        "\n",
        "  def call(self, query, value):\n",
        "    enc_states = self.W1(value)\n",
        "    dec_last_state = self.W2(query)\n",
        "    # print(enc_states.shape)\n",
        "    # print(dec_last_state.shape)\n",
        "    attn_out, attn_scores = self.attn([dec_last_state, enc_states], return_attention_scores=True)\n",
        "    return attn_out, attn_scores\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_words, embedding_size = 100, lstm_out_dim = 128, name = 'Decoder_model'):\n",
        "        super(Decoder,self).__init__(name=name)\n",
        "        self.lstm_output_dim = lstm_out_dim\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding_layer = Embedding(input_dim=num_words+1,\n",
        "                                         output_dim=self.embedding_size,\n",
        "                                         mask_zero=True,\n",
        "                                         name = 'Decoder_embedding')\n",
        "        \n",
        "        self.lstm_layer = LSTM(units = self.lstm_output_dim, \n",
        "                               return_state = True, \n",
        "                               return_sequences = True, \n",
        "                               name='Decoder_LSTM')\n",
        "        \n",
        "        self.attention_layer = LuongAttention(embedding_size)\n",
        "        self.dense_decode_layer = TimeDistributed(Dense(units = lstm_out_dim, activation='tanh'))\n",
        "\n",
        "        self.final_layer = TimeDistributed(Dense(units = num_words))\n",
        "    def call(self, inputs, encoder_states):\n",
        "        # With teacher forcing we give in input the expected src[:-1] and compare the result with the src[1:]\n",
        "        # Without teacher forcing we use the previous output and state for the next step (this is why we return results and outputs/states).\n",
        "        x = self.embedding_layer(inputs)\n",
        "        mask = self.embedding_layer.compute_mask(inputs)\n",
        "        out, h, c = self.lstm_layer(x, initial_state = encoder_states[1:], mask = mask)\n",
        "\n",
        "        #Adding attention mechanism\n",
        "        context_vector, attn_weights = self.attention_layer(out, encoder_states[0])\n",
        "        concat_out = concatenate([context_vector, out])\n",
        "        out = self.dense_decode_layer(concat_out)\n",
        "\n",
        "        #Final results\n",
        "        res = self.final_layer(out)   \n",
        "        del x,out\n",
        "        gc.collect()\n",
        "        return res, h, c, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPf1wK8lY_Qw",
        "outputId": "6bb6dfc6-4652-4476-83d7-93573dea2644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 9, 128) (1, 128) (1, 128)\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(100)\n",
        "a,b,c = encoder(tf.expand_dims(train_sequences[0][0], 0))\n",
        "print(a.shape, b.shape, c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "rz0cnU1Ceyew",
        "outputId": "e836ff04-449c-4d42-d5e7-a59f3abd41be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context vector shape: (1, 12, 100) - attention weights shape: (1, 12, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f97e1880410>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "luong_attn = LuongAttention(latent_dim = 100)\n",
        "value = np.random.rand(1,10,100) #Encoder states\n",
        "query = np.random.rand(1,12,100) #Decoder outputs\n",
        "masks = [np.ones((1,12), dtype=bool), np.ones((1,10), dtype=bool)]\n",
        "context_vector, attn_weights = luong_attn(query, value)\n",
        "print(f'Context vector shape: {context_vector.shape} - attention weights shape: {attn_weights.shape}')\n",
        "\n",
        "sns.heatmap(tf.squeeze(attn_weights).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ErtyhmIHBH",
        "outputId": "74f8227f-a43d-43f6-d27c-cda85f83b403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, None, 128) (None, 128) (None, 128)\n"
          ]
        }
      ],
      "source": [
        "encoder_input = tf.keras.Input(shape=[None], name='Encoder_inputs')\n",
        "decoder_input = tf.keras.Input(shape=[None], name='Decoder_inputs')\n",
        "\n",
        "encoder = Encoder(num_words = len(tokenizer_src.word_index), embedding_size=50, lstm_out_dim=128)\n",
        "decoder = Decoder(num_words = len(tokenizer_tgt.word_index), embedding_size=50, lstm_out_dim=128)\n",
        "\n",
        "#Build the graph\n",
        "outs, h_tot, c_tot = encoder(encoder_input)\n",
        "print(outs.shape, h_tot.shape, c_tot.shape)\n",
        "\n",
        "\n",
        "return_seq,_,_,_ = decoder(decoder_input, encoder_states=[outs, h_tot, c_tot])\n",
        "\n",
        "seq2seq_model = tf.keras.Model(inputs=[encoder_input, decoder_input], outputs=return_seq, name='Seq2Seq_Model')\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=0.5e-3)\n",
        "seq2seq_model.compile(loss=loss, optimizer=optim, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW-k33CvIHBI",
        "outputId": "f3cdde71-ba9a-4e31-c004-12ab44bc8511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Seq2Seq_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Encoder_model (Encoder)        ((None, None, 128),  787898      ['Encoder_inputs[0][0]']         \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128))                                                     \n",
            "                                                                                                  \n",
            " Decoder_model (Decoder)        ((None, None, 28497  5228473     ['Decoder_inputs[0][0]',         \n",
            "                                ),                                'Encoder_model[0][0]',          \n",
            "                                 (None, 128),                     'Encoder_model[0][1]',          \n",
            "                                 (None, 128),                     'Encoder_model[0][2]']          \n",
            "                                 (None, None, None)                                               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,016,371\n",
            "Trainable params: 6,016,371\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"Encoder_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Encoder_embedding (Embeddin  multiple                 696250    \n",
            " g)                                                              \n",
            "                                                                 \n",
            " Encoder_LSTM (LSTM)         multiple                  91648     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 787,898\n",
            "Trainable params: 787,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"Decoder_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Decoder_embedding (Embeddin  multiple                 1424900   \n",
            " g)                                                              \n",
            "                                                                 \n",
            " Decoder_LSTM (LSTM)         multiple                  91648     \n",
            "                                                                 \n",
            " luong_attention_3 (LuongAtt  multiple                 12900     \n",
            " ention)                                                         \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  multiple                 22912     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  multiple                 3676113   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,228,473\n",
            "Trainable params: 5,228,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "seq2seq_model.summary()\n",
        "encoder.summary()\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PgHIJavJ5Gg9"
      },
      "outputs": [],
      "source": [
        "# Define the callbacks for our model\n",
        "\n",
        "callbacksList = [\n",
        "                 tf.keras.callbacks.ModelCheckpoint('./chkpnt/model_saving', save_best_only=True, save_weights_only=True),\n",
        "                 tf.keras.callbacks.EarlyStopping(patience=3)\n",
        "                #  tf.keras.callbacks.TensorBoard()\n",
        "                 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKBJXFEpIHBM",
        "outputId": "297c4ad6-c0cb-4947-97bd-40e2b56d4a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3169/3520 [==========================>...] - ETA: 28s - loss: 1.6729 - accuracy: 0.3209"
          ]
        }
      ],
      "source": [
        "seq2seq_model.fit(gen_train_ds, \n",
        "                  epochs=EPOCHS, \n",
        "                  steps_per_epoch=SPE_TRAIN,\n",
        "                  validation_data=gen_valid_ds,\n",
        "                  validation_steps=SPE_VALID\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2MCpkpNCc0R"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFGmLFYAVJJD"
      },
      "outputs": [],
      "source": [
        "# %tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y61ldQQLIHBO"
      },
      "outputs": [],
      "source": [
        "def evaluate_sentence(sentence, debug=False, viz_attn=False):\n",
        "  sentence = [re.sub(r'([!?.,;])', r' \\1', sentence)]\n",
        "  sentence = [' '.join(sentence[0].split()[::-1])]\n",
        "  seq_sentence = tokenizer_src.texts_to_sequences(sentence)\n",
        "  seq_sentence = tf.convert_to_tensor(seq_sentence)\n",
        "  #Pass the sequence to the encoder\n",
        "  enc_out, enc_h, enc_c = encoder(seq_sentence)\n",
        "  dec_h = enc_h\n",
        "  dec_c = enc_c\n",
        "\n",
        "  out_seq = []\n",
        "  eos_idx = tokenizer_tgt.word_index['<eos>']\n",
        "  curr_output = [tokenizer_tgt.word_index['<sos>']]\n",
        "  for i in range(20):\n",
        "      dec_input = tf.convert_to_tensor(curr_output)\n",
        "      dec_input = tf.expand_dims(dec_input, axis=0)\n",
        "      if debug:\n",
        "        print(f'Input: {dec_input}')\n",
        "      out, h_, c_ = decoder(dec_input, encoder_states=[enc_out, dec_h, dec_c])\n",
        "      out_idx = tf.squeeze(tf.argmax(out, axis=-1))\n",
        "      if debug:\n",
        "        print(f'Next output: {out_idx}')\n",
        "      dec_h = h_\n",
        "      dec_c = c_\n",
        "      \n",
        "      if out_idx == eos_idx:\n",
        "          break\n",
        "      \n",
        "      out_seq.append(out_idx.numpy())\n",
        "      if debug:\n",
        "        print(f'Output sequence: {out_seq}')\n",
        "      curr_output = [out_idx.numpy()]\n",
        "\n",
        "  print('Final sequence: '+' '.join(tokenizer_tgt.index_word[i] for i in out_seq))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm40hjklm4U2"
      },
      "outputs": [],
      "source": [
        "evaluate_sentence(\"i want to kill you\")\n",
        "evaluate_sentence(\"What are you doing?\")\n",
        "evaluate_sentence(\"Is this a joke?\")\n",
        "evaluate_sentence(\"Not my problem\")\n",
        "evaluate_sentence(\"I'm bored\")\n",
        "evaluate_sentence(\"Is there something that is bothering you?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWYsp5MHDAN-"
      },
      "source": [
        "# Using TF-Addons: Seq2Seq module\n",
        "\n",
        "The Encoder is already done. We need to define another type of Decoder that uses the Attention mechanism and the training sampler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzXNUVIODG52"
      },
      "outputs": [],
      "source": [
        "class DecoderAddon(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_words, embedding_size = 100, lstm_out_dim = 128, name = 'Decoder_model'):\n",
        "    super().__init__()\n",
        "    self.num_words = num_words\n",
        "    self.embedding_size = embedding_size\n",
        "    self.lstm_out_dim = lstm_out_dim\n",
        "    self.name\n",
        "    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "\n",
        "\n",
        "    self.embedding_layer = Embedding(input_dim=num_words+1,\n",
        "                                         output_dim=self.embedding_size,\n",
        "                                         name = 'Decoder_embedding')\n",
        "    \n",
        "    self.rnn_cell = LSTMCell(units=lstm_out_dim,\n",
        "                             name='Decoder_LSTM_Cell')\n",
        "    \n",
        "    self.attn_mechanism = tfa.seq2seq.LuongAttention(units=lstm_out_dim)\n",
        "    self.recurrent_layer = tfa.seq2seq.AttentionWrapper(self.rnn_cell, \n",
        "                                                        self.attn_mechanism, \n",
        "                                                        attention_layer_size=self.lstm_out_dim)\n",
        "    self.prediction_layer = Dense(units=self.num_words)\n",
        "    self.decoder_layer = tfa.seq2seq.BasicDecoder(self.recurrent_layer, sampler=self.sampler, output_layer=self.prediction_layer)\n",
        "\n",
        "  def build_initial_state(self, batch_sz, encoder_state, Dtype):\n",
        "    decoder_initial_state = self.recurrent_layer.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n",
        "    decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
        "    return decoder_initial_state  \n",
        "\n",
        "  def call(self, inputs, encoder_states):\n",
        "    x = self.embedding_layer(inputs)\n",
        "    mask = self.embedding_layer.compute_mask(inputs)\n",
        "    outputs, _, _ = self.decoder_layer(x, initial_state=encoder_states, mask = mask)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p0RKV1RMVAo"
      },
      "outputs": [],
      "source": [
        "encoder_addon = Encoder(len(tokenizer_src.word_index), embedding_size=50, lstm_out_dim=128)\n",
        "decoder_addon = DecoderAddon(len(tokenizer_tgt.word_index), embedding_size=50, lstm_out_dim=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nneBIE7NOJA_"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric_fn = tf.keras.metrics.SparseCategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGmUm89vMhHN"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(enc_inp, dec_inp, dec_out, enc_hidden=None):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_h, enc_c = encoder_addon(enc_inp, enc_hidden)\n",
        "\n",
        "    # Set the AttentionMechanism object with encoder_outputs\n",
        "    decoder_addon.attn_mechanism.setup_memory(enc_output)\n",
        "\n",
        "    # Create AttentionWrapperState as initial_state for decoder\n",
        "    decoder_initial_state = decoder_addon.build_initial_state(BS_TRAIN, [enc_h, enc_c], tf.float32)\n",
        "    pred = decoder_addon(dec_inp, decoder_initial_state)\n",
        "    logits = pred.rnn_output\n",
        "    loss = loss_fn(dec_out, logits)\n",
        "    reshaped_logits = tf.reshape(tf.nn.softmax(logits), (logits.shape[0],dec_out.shape[-1], logits.shape[-1]))\n",
        "    #Update metric state\n",
        "    metric_fn.update_state(dec_out, reshaped_logits)\n",
        "\n",
        "  variables = encoder_addon.trainable_variables + decoder_addon.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss\n",
        "\n",
        "@tf.function\n",
        "def valid_step(enc_inp, dec_inp, dec_out, enc_hidden=None):\n",
        "  loss = 0\n",
        "\n",
        "  enc_output, enc_h, enc_c = encoder_addon(enc_inp, enc_hidden)\n",
        "  decoder_addon.attn_mechanism.setup_memory(enc_output)\n",
        "  # Create AttentionWrapperState as initial_state for decoder\n",
        "  decoder_initial_state = decoder_addon.build_initial_state(BS_VALID, [enc_h, enc_c], tf.float32)\n",
        "  pred = decoder_addon(dec_inp, decoder_initial_state)\n",
        "  logits = pred.rnn_output\n",
        "  loss = loss_fn(dec_out, logits)\n",
        "  reshaped_logits = tf.reshape(tf.nn.softmax(logits), (logits.shape[0],dec_out.shape[-1], logits.shape[-1]))\n",
        "  #Update metric state\n",
        "  metric_fn.update_state(dec_out, reshaped_logits)\n",
        "\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xUbj0y_Oia2"
      },
      "outputs": [],
      "source": [
        "print('Started training.')\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = None\n",
        "  total_loss = 0\n",
        "  total_acc = 0\n",
        "  valid_loss = 0\n",
        "  valid_acc = 0\n",
        "\n",
        "  #Train on dataset\n",
        "  metric_fn.reset_state()\n",
        "  for (batch, ((enc_inp, dec_inp), dec_out)) in enumerate(gen_train_ds.take(SPE_TRAIN)):\n",
        "    batch_loss = train_step(enc_inp, dec_inp, dec_out, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "    total_acc = metric_fn.result()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('\\r '*200,end='')\n",
        "      print('\\rTrain Epoch {} Batch {} Loss {:.3f} Accuracy {:.3f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy(),\n",
        "                                                   total_acc),end='')\n",
        "  metric_fn.reset_state()\n",
        "  print('-----')\n",
        "  for (batch, ((enc_inp, dec_inp), dec_out)) in enumerate(gen_valid_ds.take(SPE_VALID)):\n",
        "    batch_valid_loss = valid_step(enc_inp, dec_inp, dec_out, enc_hidden)\n",
        "    valid_loss += batch_valid_loss\n",
        "    valid_acc = metric_fn.result()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('\\r '*200)\n",
        "      print('\\rValid Epoch {} Batch {} Loss {:.4f} Accuracy {:.3f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   valid_loss.numpy(),\n",
        "                                                   total_acc))\n",
        "    \n",
        "  print(f'Epoch {epoch+1} - ({time.time()-start}s) - Loss {total_loss/SPE_TRAIN:.3f} - Acc. {total_acc:.3f} - Val.Loss {valid_loss/SPE_VALID:.3f} - Val.Acc {valid_acc:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_sentence(sentence_in, debug=False, viz_attn=False):\n",
        "  sentence = [re.sub(r'([!?.,;])', r' \\1', sentence_in)]\n",
        "  sentence = [' '.join(sentence[0].split()[::-1])]\n",
        "  seq_sentence = tokenizer_src.texts_to_sequences(sentence)\n",
        "  seq_sentence = tf.convert_to_tensor(seq_sentence)\n",
        "  #Pass the sequence to the encoder\n",
        "\n",
        "  enc_start_state = [tf.zeros((1, encoder_addon.lstm_output_dim)), tf.zeros((1, encoder_addon.lstm_output_dim))]\n",
        "  enc_out, enc_h, enc_c = encoder_addon(seq_sentence)\n",
        "\n",
        "  out_seq = []\n",
        "  eos_idx = tokenizer_tgt.word_index['<eos>']\n",
        "  curr_output = [tokenizer_tgt.word_index['<sos>']]\n",
        "\n",
        "  greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "  decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder_addon.recurrent_layer, sampler=greedy_sampler, output_layer=decoder_addon.prediction_layer)\n",
        "  decoder_addon.attn_mechanism.setup_memory(enc_out)\n",
        "  # set decoder_initial_state\n",
        "  decoder_initial_state = decoder_addon.build_initial_state(1, [enc_h, enc_c], tf.float32)\n",
        "\n",
        "\n",
        "  ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \n",
        "  ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \n",
        "  ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\n",
        "\n",
        "  decoder_embedding_matrix = decoder_addon.embedding_layer.variables[0]\n",
        "\n",
        "  outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = curr_output, end_token= eos_idx, initial_state=decoder_initial_state)\n",
        "  out_seq = outputs.sample_id.numpy().squeeze()\n",
        "  print(f'Original sentence: {sentence_in}')\n",
        "  print('Final sequence: '+' '.join(tokenizer_tgt.index_word[i] for i in out_seq[:-1]))"
      ],
      "metadata": {
        "id": "buNqs4ikiz6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_sentence('I need to talk!')"
      ],
      "metadata": {
        "id": "s_rYkcYgp6QI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "neural_machine_translation_lstm_seq2seq_network.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}